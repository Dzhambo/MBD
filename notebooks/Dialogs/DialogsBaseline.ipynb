{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62b2f76-81e1-4693-8d22-dead6fc1230c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:56:13.186171Z",
     "iopub.status.busy": "2024-05-25T10:56:13.186055Z",
     "iopub.status.idle": "2024-05-25T10:56:13.188190Z",
     "shell.execute_reply": "2024-05-25T10:56:13.188098Z",
     "shell.execute_reply.started": "2024-05-25T10:56:13.186141Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "from ptls.data_load import IterableChain\n",
    "from datetime import datetime\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3feffeb4-3d93-404b-bd3f-295d0284f01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:56:14.654108Z",
     "iopub.status.busy": "2024-05-25T10:56:14.653984Z",
     "iopub.status.idle": "2024-05-25T10:56:14.655232Z",
     "shell.execute_reply": "2024-05-25T10:56:14.655142Z",
     "shell.execute_reply.started": "2024-05-25T10:56:14.654071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = 'dial_train_prepr.parquet'\n",
    "valid_data_path = 'dial_test_prepr.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b926d-6ad8-4dc1-aa63-a62e5688b4bb",
   "metadata": {},
   "source": [
    "# Mean embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3e678-001c-416d-93d3-a40e5821f6ef",
   "metadata": {},
   "source": [
    "## Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c282dc5-db3b-4757-853e-ddb375fa078f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T10:05:02.407753Z",
     "iopub.status.busy": "2024-05-20T10:05:02.407703Z",
     "iopub.status.idle": "2024-05-20T10:05:02.415137Z",
     "shell.execute_reply": "2024-05-20T10:05:02.415070Z",
     "shell.execute_reply.started": "2024-05-20T10:05:02.407727Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GetSplit(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_month,\n",
    "        end_month,\n",
    "        year=2022,\n",
    "        col_id='client_id',\n",
    "        col_time='event_time'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start_month = start_month\n",
    "        self.end_month = end_month\n",
    "        self._year = year\n",
    "        self._col_id = col_id\n",
    "        self._col_time = col_time\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for rec in self._src:\n",
    "            for month in range(self.start_month, self.end_month+1):\n",
    "                features = rec[0] if type(rec) is tuple else rec\n",
    "                features = features.copy()\n",
    "                \n",
    "                if month == 12:\n",
    "                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n",
    "                else:\n",
    "                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n",
    "                    \n",
    "                year_event_time = datetime(self._year, 1, 1).timestamp()\n",
    "                \n",
    "                mask = features[self._col_time] < month_event_time\n",
    "                \n",
    "                for key, tens in features.items():\n",
    "                    if key.startswith('target'):\n",
    "                        features[key] = tens[month - 1].tolist()    \n",
    "                    elif key == 'embedding':\n",
    "                        features[key] = torch.tensor(tens.tolist())[mask]\n",
    "                        if len(features[key]) > 1:\n",
    "                            features[key] = torch.mean(features[key], dim=0)\n",
    "                        elif len(features[key]) == 1:\n",
    "                            features[key] = features[key][0]\n",
    "                        elif len(features[key]) == 0:\n",
    "                            features[key] = torch.zeros(768)\n",
    "                            \n",
    "                features[self._col_id] += '_month=' + str(month)\n",
    "\n",
    "                yield features\n",
    "\n",
    "def collate_feature_dict_with_target(batch, col_id='client_id', targets=False):\n",
    "    batch_ids = []\n",
    "    target_cols = []\n",
    "    for sample in batch:\n",
    "        batch_ids.append(sample[col_id])\n",
    "        del sample[col_id]\n",
    "        \n",
    "        if targets:\n",
    "            target_cols.append([sample[f'target_{i}'] for i in range(1, 5)])\n",
    "            del sample['target_1']\n",
    "            del sample['target_2']\n",
    "            del sample['target_3']\n",
    "            del sample['target_4']\n",
    "            \n",
    "    padded_batch = collate_feature_dict(batch)\n",
    "    if targets:\n",
    "        return padded_batch, batch_ids, target_cols\n",
    "    return padded_batch, batch_ids    \n",
    "\n",
    "def to_pandas(x):\n",
    "    expand_cols = []\n",
    "    scalar_features = {}\n",
    "\n",
    "    for k, v in x.items():\n",
    "        if type(v) is torch.Tensor:\n",
    "            v = v.cpu().numpy()\n",
    "\n",
    "        if type(v) is list or len(v.shape) == 1:\n",
    "            scalar_features[k] = v\n",
    "        elif len(v.shape) == 2:\n",
    "            expand_cols.append(k)\n",
    "        else:\n",
    "            scalar_features[k] = None\n",
    "\n",
    "    dataframes = [pd.DataFrame(scalar_features)]\n",
    "    for col in expand_cols:\n",
    "        v = x[col].cpu().numpy()\n",
    "        dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n",
    "\n",
    "    return pd.concat(dataframes, axis=1)\n",
    "\n",
    "def get_dataset(dl, target=True):\n",
    "    dataset = []\n",
    "    for batch in tqdm(dl):\n",
    "        if target:\n",
    "            out, batch_ids, target_cols = batch[0].payload['embedding'], batch[1], np.squeeze([batch[2]])\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'target_1': target_cols[:, 0],\n",
    "                'target_2': target_cols[:, 1],\n",
    "                'target_3': target_cols[:, 2],\n",
    "                'target_4': target_cols[:, 3],\n",
    "                'embs': out\n",
    "            }\n",
    "        else:\n",
    "            out, batch_ids = batch[0].payload['embedding'], batch[1]\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'embs': out\n",
    "            }\n",
    "        dataset.append(to_pandas(x_out))\n",
    "    return pd.concat(dataset, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9a060d-b07c-472a-9f02-a89106a07a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T10:05:02.415286Z",
     "iopub.status.busy": "2024-05-20T10:05:02.415238Z",
     "iopub.status.idle": "2024-05-20T10:05:02.416903Z",
     "shell.execute_reply": "2024-05-20T10:05:02.416839Z",
     "shell.execute_reply.started": "2024-05-20T10:05:02.415260Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTorchTmp(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for rec in self._src:\n",
    "            features = rec[0] if type(rec) is tuple else rec\n",
    "            features = features.copy()\n",
    "            for key, tens in features.items():\n",
    "                if key == 'embedding':\n",
    "                    features[key] = torch.tensor(tens.tolist())\n",
    "                    if len(features[key]) > 1:\n",
    "                        features[key] = torch.mean(features[key], dim=0)\n",
    "                    elif len(features[key]) == 1:\n",
    "                        features[key] = features[key][0]\n",
    "                    elif len(features[key]) == 0:\n",
    "                        features[key] = torch.zeros(768)\n",
    "\n",
    "            yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bb30b-d0cc-4518-9eeb-936b7da67dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T10:05:02.417038Z",
     "iopub.status.busy": "2024-05-20T10:05:02.416992Z",
     "iopub.status.idle": "2024-05-20T10:05:02.418727Z",
     "shell.execute_reply": "2024-05-20T10:05:02.418662Z",
     "shell.execute_reply.started": "2024-05-20T10:05:02.417013Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_process = IterableChain(\n",
    "            FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            GetSplit(start_month=1, end_month=12),\n",
    "            ToTorch(),\n",
    ")\n",
    "\n",
    "test_process = IterableChain(\n",
    "            FeatureFilter(keep_feature_names=['client_id'], drop_feature_names=['target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            ToTorchTmp(),\n",
    "            ToTorch()\n",
    ")\n",
    "\n",
    "\n",
    "train = ParquetDataset([train_data_path], post_processing=train_process)\n",
    "test = ParquetDataset([valid_data_path], post_processing=test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a33f588-1b7a-447a-8e94-322a7d389b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T10:05:02.418857Z",
     "iopub.status.busy": "2024-05-20T10:05:02.418810Z",
     "iopub.status.idle": "2024-05-20T10:05:02.419907Z",
     "shell.execute_reply": "2024-05-20T10:05:02.419848Z",
     "shell.execute_reply.started": "2024-05-20T10:05:02.418831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_train_dl = DataLoader(\n",
    "        dataset=train,\n",
    "        collate_fn=partial(collate_feature_dict_with_target, targets=True),\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        batch_size=512,\n",
    "    )\n",
    "\n",
    "inference_test_dl = DataLoader(\n",
    "        dataset=test,\n",
    "        collate_fn=collate_feature_dict_with_target,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        batch_size=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138790b4-c9f7-482c-88f7-3460df9bf4e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T10:05:02.420033Z",
     "iopub.status.busy": "2024-05-20T10:05:02.419987Z",
     "iopub.status.idle": "2024-05-20T10:05:02.420980Z",
     "shell.execute_reply": "2024-05-20T10:05:02.420918Z",
     "shell.execute_reply.started": "2024-05-20T10:05:02.420008Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca4c69-7129-4037-9cfd-346714428629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-20T10:05:02.421105Z",
     "iopub.status.busy": "2024-05-20T10:05:02.421059Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(inference_train_dl)\n",
    "train_dataset.to_parquet(\"dial_baseline_train.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")\n",
    "del train_dataset\n",
    "\n",
    "test_dataset = get_dataset(inference_test_dl, target=False)\n",
    "test_dataset.to_parquet(\"dial_baseline_test.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47953cf-ffb4-4ba3-9c4b-e10f11883015",
   "metadata": {},
   "source": [
    "# Downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af83b65b-1af5-413d-bbea-a9399e13c5f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:55:33.401731Z",
     "iopub.status.busy": "2024-05-25T10:55:33.401624Z",
     "iopub.status.idle": "2024-05-25T10:55:33.405865Z",
     "shell.execute_reply": "2024-05-25T10:55:33.405798Z",
     "shell.execute_reply.started": "2024-05-25T10:55:33.401697Z"
    }
   },
   "outputs": [],
   "source": [
    "class Downstream:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path,\n",
    "        test_path,\n",
    "        params,\n",
    "        result_path,\n",
    "        col_id='client_id',\n",
    "        targets=(\n",
    "            'target_1',\n",
    "            'target_2',\n",
    "            'target_3',\n",
    "            'target_4'\n",
    "        )\n",
    "    ):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "\n",
    "        self.col_id = col_id\n",
    "        self.all_targets = targets\n",
    "        self.params = params\n",
    "        self.result_path = result_path\n",
    "        self.drop_feat = list(self.all_targets) + [self.col_id]\n",
    "        \n",
    "    def fit(self):\n",
    "        \n",
    "        train_embeddings = pd.read_parquet(self.train_path)\n",
    "        X_train = train_embeddings.drop(columns=self.drop_feat)\n",
    "\n",
    "        clfs = dict()\n",
    "        for col_target in self.all_targets:\n",
    "            clf = ltb.LGBMClassifier(**self.params)\n",
    "            y_train = train_embeddings[col_target]\n",
    "            clf.fit(X_train, y_train)\n",
    "            print(f'Model fitted, target: {col_target}')\n",
    "            clfs[col_target] = clf\n",
    "        return clfs\n",
    "\n",
    "    def get_scores(\n",
    "        self, \n",
    "        clfs\n",
    "    ):\n",
    "        scores = pd.DataFrame([])\n",
    "\n",
    "        test_embeddings_curr = pd.read_parquet(self.test_path).drop_duplicates('client_id')\n",
    "        X_test = test_embeddings_curr.drop(columns=[self.col_id])\n",
    "        ids = test_embeddings_curr[self.col_id]\n",
    "        scores[self.col_id] = ids\n",
    "            \n",
    "        for col_target in self.all_targets:\n",
    "            clf = clfs[col_target]\n",
    "            score = clf.predict_proba(X_test)[:, 1]\n",
    "            scores[col_target] = score\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    def run(self):\n",
    "        clfs = self.fit()\n",
    "        scores = self.get_scores(clfs)\n",
    "        \n",
    "        scores.to_csv(self.result_path)\n",
    "            \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb35e34-f6c6-479b-ac8f-04bef0e589a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:56:55.633234Z",
     "iopub.status.busy": "2024-05-25T10:56:55.633089Z",
     "iopub.status.idle": "2024-05-25T10:56:55.856331Z",
     "shell.execute_reply": "2024-05-25T10:56:55.856171Z",
     "shell.execute_reply.started": "2024-05-25T10:56:55.633203Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import lightgbm as ltb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02f8cf-74e8-4d97-958e-cb517b87cfbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T10:56:55.898085Z",
     "iopub.status.busy": "2024-05-25T10:56:55.897981Z",
     "iopub.status.idle": "2024-05-25T11:26:29.317685Z",
     "shell.execute_reply": "2024-05-25T11:26:29.317560Z",
     "shell.execute_reply.started": "2024-05-25T10:56:55.898034Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      \"objective\": \"binary\",\n",
    "      \"subsample\": 0.5,\n",
    "      \"subsample_freq\": 1,\n",
    "      \"learning_rate\": 0.02,\n",
    "      \"feature_fraction\": 0.75,\n",
    "      \"max_depth\": 6,\n",
    "      \"lambda_l1\": 1,\n",
    "      \"lambda_l2\": 1,\n",
    "      \"min_data_in_leaf\": 50,\n",
    "      \"random_state\": 42,\n",
    "      \"n_jobs\": 8,\n",
    "}\n",
    "\n",
    "dw = Downstream(\n",
    "    train_path=\"dial_baseline_train.parquet\",\n",
    "    test_path=\"dial_baseline_test.parquet\",\n",
    "    params=params,\n",
    "    result_path='baseline_dial.csv' \n",
    ")\n",
    "\n",
    "scores = dw.run()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0d9bcc-28bb-4f3f-a781-4fda67b608d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:26:29.317876Z",
     "iopub.status.busy": "2024-05-25T11:26:29.317818Z",
     "iopub.status.idle": "2024-05-25T11:26:33.939738Z",
     "shell.execute_reply": "2024-05-25T11:26:33.939595Z",
     "shell.execute_reply.started": "2024-05-25T11:26:29.317847Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "! python ../scripts/evaluate.py --ref_df_public public_target.parquet --ref_df_private private_target.parquet --pred_df baseline_dial.csv --public_result_path dial_public_score.txt --private_result_path dial_private_score.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kalash_cuda116_ptls",
   "language": "python",
   "name": "kalash_cuda116_ptls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
