{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f7fe90-2d0c-4cce-853a-079ffb802c49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:29.844522Z",
     "iopub.status.busy": "2024-05-23T10:46:29.844413Z",
     "iopub.status.idle": "2024-05-23T10:46:32.814209Z",
     "shell.execute_reply": "2024-05-23T10:46:32.814045Z",
     "shell.execute_reply.started": "2024-05-23T10:46:29.844476Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ptls.data_load import IterableChain\n",
    "from ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\n",
    "from ptls.data_load.iterable_processing.category_size_clip import CategorySizeClip\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "from ptls.data_load.iterable_processing.target_move import TargetMove\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.data_load.iterable_processing import FeatureBinScaler\n",
    "from ptls.frames.coles import ColesIterableDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "from itertools import groupby\n",
    "from functools import reduce\n",
    "from operator import iadd\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from ptls.data_load.feature_dict import FeatureDict\n",
    "from ptls.frames.coles.split_strategy import AbsSplit\n",
    "\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder\n",
    "from ptls.nn.seq_encoder.rnn_encoder import RnnEncoder\n",
    "from ptls.frames.coles.coles_module import CoLESModule\n",
    "from ptls.frames.inference_module import InferenceModule\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from tqdm.auto import tqdm\n",
    "import lightgbm as ltb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af38a1fc-763c-4c6b-bcf1-ff739b9862f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.814972Z",
     "iopub.status.busy": "2024-05-23T10:46:32.814910Z",
     "iopub.status.idle": "2024-05-23T10:46:32.834837Z",
     "shell.execute_reply": "2024-05-23T10:46:32.834767Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.814939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ptls.frames.bert import  MlmDataset, MlmIterableDataset\n",
    "from ptls.frames.tabformer.tabformer_dataset import TabformerDataset,  TabformerIterableDataset\n",
    "from ptls.nn import TabFormerFeatureEncoder, TransformerEncoder\n",
    "from ptls.frames.tabformer.tabformer_module import TabformerPretrainModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af005486-1ad4-466e-9119-935c91ffea2e",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f9be98-2712-41bd-a09d-fa18ce10b76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.834977Z",
     "iopub.status.busy": "2024-05-23T10:46:32.834930Z",
     "iopub.status.idle": "2024-05-23T10:46:32.835577Z",
     "shell.execute_reply": "2024-05-23T10:46:32.835511Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.834949Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_conf = {\n",
    "    'category_max_size': {\n",
    "        'geohash_4': 4999,\n",
    "        'geohash_5': 4999,\n",
    "        'geohash_6': 4999,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7d5a89-9480-4b6f-bfd0-7414e25d6e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.835737Z",
     "iopub.status.busy": "2024-05-23T10:46:32.835672Z",
     "iopub.status.idle": "2024-05-23T10:46:32.836893Z",
     "shell.execute_reply": "2024-05-23T10:46:32.836825Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.835706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = 'geo_train_prepr.parquet'\n",
    "valid_data_path = 'geo_test_prepr.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387d4b8c-31be-4825-bf0d-8313500841ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.837054Z",
     "iopub.status.busy": "2024-05-23T10:46:32.836996Z",
     "iopub.status.idle": "2024-05-23T10:46:32.838005Z",
     "shell.execute_reply": "2024-05-23T10:46:32.837937Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.837022Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "process = IterableChain(\n",
    "            SeqLenFilter(min_seq_len=32),\n",
    "            ISeqLenLimit(max_seq_len=4096),\n",
    "            FeatureFilter(drop_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            CategorySizeClip(dataset_conf['category_max_size']),\n",
    "            ToTorch()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cbc69d-ce3a-4dfe-8bf7-0b0023250b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.838161Z",
     "iopub.status.busy": "2024-05-23T10:46:32.838101Z",
     "iopub.status.idle": "2024-05-23T10:46:32.838999Z",
     "shell.execute_reply": "2024-05-23T10:46:32.838928Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.838134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = ParquetDataset([train_data_path], post_processing=process, shuffle_files=True)\n",
    "valid = ParquetDataset([valid_data_path], post_processing=process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18eacdd9-e49d-4d84-a096-3463857c4056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.839152Z",
     "iopub.status.busy": "2024-05-23T10:46:32.839094Z",
     "iopub.status.idle": "2024-05-23T10:46:32.840064Z",
     "shell.execute_reply": "2024-05-23T10:46:32.840000Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.839123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = TabformerIterableDataset(\n",
    "    data=train,\n",
    "    min_len=80,\n",
    "    max_len=300\n",
    ")\n",
    "\n",
    "valid_ds = MlmIterableDataset(\n",
    "    data=train,\n",
    "    min_len=80,\n",
    "    max_len=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3566e5-fe44-4b53-8075-3d04f7a9ca64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.840217Z",
     "iopub.status.busy": "2024-05-23T10:46:32.840161Z",
     "iopub.status.idle": "2024-05-23T10:46:32.841355Z",
     "shell.execute_reply": "2024-05-23T10:46:32.841290Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.840189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = PtlsDataModule(\n",
    "    train_data=train_ds,\n",
    "    train_num_workers=16,\n",
    "    train_batch_size=256,\n",
    "    valid_data=valid_ds,\n",
    "    valid_num_workers=16,\n",
    "    valid_batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d99af1-02ec-4dc7-9672-742c03b65696",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ecf4a6-6432-4c34-ad68-b652e3b652a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:32.841525Z",
     "iopub.status.busy": "2024-05-23T10:46:32.841469Z",
     "iopub.status.idle": "2024-05-23T10:46:33.688390Z",
     "shell.execute_reply": "2024-05-23T10:46:33.686280Z",
     "shell.execute_reply.started": "2024-05-23T10:46:32.841496Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003, \n",
    "    embeddings={\n",
    "        'geohash_4': {'in': 5000, 'out': 24},\n",
    "        \"geohash_5\": {'in': 5000, \"out\": 24},\n",
    "        \"geohash_6\": {'in': 5000, \"out\": 24},\n",
    "      }\n",
    ")\n",
    "\n",
    "feature_encoder = TabFormerFeatureEncoder(3, 24)\n",
    "seq_encoder = TransformerEncoder(\n",
    "    input_size=3*24,\n",
    "    n_heads=2,\n",
    "    n_layers=2,\n",
    "    use_positional_encoding=False\n",
    ")\n",
    "\n",
    "model = TabformerPretrainModule(\n",
    "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "    seq_encoder=seq_encoder,\n",
    "    feature_encoder=feature_encoder,\n",
    "    mask_prob=0.2,\n",
    "    total_steps=50000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da41bbb-06e9-434d-904a-268f3916b5b3",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b977403-28ef-46b5-b976-2e1a81da8329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:33.703230Z",
     "iopub.status.busy": "2024-05-23T10:46:33.702740Z",
     "iopub.status.idle": "2024-05-23T10:46:33.778840Z",
     "shell.execute_reply": "2024-05-23T10:46:33.778180Z",
     "shell.execute_reply.started": "2024-05-23T10:46:33.70297Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import logging\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=15,\n",
    "    limit_val_batches=5000,\n",
    "    gpus=[0],\n",
    "    enable_progress_bar=False,\n",
    "    gradient_clip_val=0.5,\n",
    "    logger=pl.loggers.TensorBoardLogger(\n",
    "        save_dir='./logdir',\n",
    "        name='baseline_result_tabformer'\n",
    "    ),\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='step'),\n",
    "        pl.callbacks.ModelCheckpoint(every_n_train_steps=5000, save_top_k=-1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2fd4a-b538-4a1a-90ac-8486e1905fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T10:46:33.780200Z",
     "iopub.status.busy": "2024-05-23T10:46:33.779670Z",
     "iopub.status.idle": "2024-05-23T15:11:34.223666Z",
     "shell.execute_reply": "2024-05-23T15:11:34.223510Z",
     "shell.execute_reply.started": "2024-05-23T10:46:33.77990Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cde3832-e5d9-419f-881b-3584cd0230c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.223859Z",
     "iopub.status.busy": "2024-05-23T15:11:34.223804Z",
     "iopub.status.idle": "2024-05-23T15:11:34.271800Z",
     "shell.execute_reply": "2024-05-23T15:11:34.271657Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.223832Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.seq_encoder, '../models/geo_baseline_tabformer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c70247-2a1d-4efb-9441-cce78b7b9500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.272998Z",
     "iopub.status.busy": "2024-05-23T15:11:34.272953Z",
     "iopub.status.idle": "2024-05-23T15:11:34.274746Z",
     "shell.execute_reply": "2024-05-23T15:11:34.274687Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.272973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.seq_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df91ab4-b046-4503-8391-bc6378ada9b2",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29ee789b-cb32-4909-9090-7a2d87ceb855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.274906Z",
     "iopub.status.busy": "2024-05-23T15:11:34.274859Z",
     "iopub.status.idle": "2024-05-23T15:11:34.276125Z",
     "shell.execute_reply": "2024-05-23T15:11:34.276068Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.274880Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "from datetime import datetime\n",
    "from ptls.data_load.padded_batch import PaddedBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7333db4-0930-4776-aa39-c47cdac276f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.276328Z",
     "iopub.status.busy": "2024-05-23T15:11:34.276278Z",
     "iopub.status.idle": "2024-05-23T15:11:34.282030Z",
     "shell.execute_reply": "2024-05-23T15:11:34.281966Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.276300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GetSplit(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_month,\n",
    "        end_month,\n",
    "        year=2022,\n",
    "        col_id='client_id',\n",
    "        col_time='event_time'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start_month = start_month\n",
    "        self.end_month = end_month\n",
    "        self._year = year\n",
    "        self._col_id = col_id\n",
    "        self._col_time = col_time\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for rec in self._src:\n",
    "            for month in range(self.start_month, self.end_month+1):\n",
    "                features = rec[0] if type(rec) is tuple else rec\n",
    "                features = features.copy()\n",
    "                \n",
    "                if month == 12:\n",
    "                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n",
    "                else:\n",
    "                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n",
    "                    \n",
    "                year_event_time = datetime(self._year, 1, 1).timestamp()\n",
    "                \n",
    "                mask = features[self._col_time] < month_event_time\n",
    "                \n",
    "                for key, tensor in features.items():\n",
    "                    if key.startswith('target'):\n",
    "                        features[key] = tensor[month - 1].tolist()    \n",
    "                    elif key != self._col_id:\n",
    "                        features[key] = tensor[mask] \n",
    "                            \n",
    "                features[self._col_id] += '_month=' + str(month)\n",
    "\n",
    "                yield features\n",
    "                \n",
    "def collate_feature_dict_with_target(batch, col_id='client_id', targets=False):\n",
    "    batch_ids = []\n",
    "    target_cols = []\n",
    "    for sample in batch:\n",
    "        batch_ids.append(sample[col_id])\n",
    "        del sample[col_id]\n",
    "        \n",
    "        if targets:\n",
    "            target_cols.append([sample[f'target_{i}'] for i in range(1, 5)])\n",
    "            del sample['target_1']\n",
    "            del sample['target_2']\n",
    "            del sample['target_3']\n",
    "            del sample['target_4']\n",
    "            \n",
    "    padded_batch = collate_feature_dict(batch)\n",
    "    if targets:\n",
    "        return padded_batch, batch_ids, target_cols\n",
    "    return padded_batch, batch_ids\n",
    "\n",
    "\n",
    "class InferenceModuleMultimodal(pl.LightningModule):\n",
    "    def __init__(self, model, pandas_output=True, drop_seq_features=True, model_out_name='out'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.pandas_output = pandas_output\n",
    "        self.drop_seq_features = drop_seq_features\n",
    "        self.model_out_name = model_out_name\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_len = len(x)\n",
    "        if x_len == 3:\n",
    "            x, batch_ids, target_cols = x\n",
    "        else: \n",
    "            x, batch_ids = x\n",
    "            \n",
    "        out = self.model(x)\n",
    "        if x_len == 3:\n",
    "            target_cols = torch.tensor(target_cols)\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'target_1': target_cols[:, 0],\n",
    "                'target_2': target_cols[:, 1],\n",
    "                'target_3': target_cols[:, 2],\n",
    "                'target_4': target_cols[:, 3],\n",
    "                self.model_out_name: out\n",
    "            }\n",
    "        else:\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                self.model_out_name: out\n",
    "            }\n",
    "\n",
    "        if self.pandas_output:\n",
    "            return self.to_pandas(x_out)\n",
    "        return x_out\n",
    "\n",
    "    @staticmethod\n",
    "    def to_pandas(x):\n",
    "        expand_cols = []\n",
    "        scalar_features = {}\n",
    "\n",
    "        for k, v in x.items():\n",
    "            if type(v) is torch.Tensor:\n",
    "                v = v.cpu().numpy()\n",
    "\n",
    "            if type(v) is list or len(v.shape) == 1:\n",
    "                scalar_features[k] = v\n",
    "            elif len(v.shape) == 2:\n",
    "                expand_cols.append(k)\n",
    "            else:\n",
    "                scalar_features[k] = None\n",
    "\n",
    "        dataframes = [pd.DataFrame(scalar_features)]\n",
    "        for col in expand_cols:\n",
    "            v = x[col].cpu().numpy()\n",
    "            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n",
    "\n",
    "        return pd.concat(dataframes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12dec37c-4975-494a-9425-a5d4f8d56626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.282199Z",
     "iopub.status.busy": "2024-05-23T15:11:34.282148Z",
     "iopub.status.idle": "2024-05-23T15:11:34.283627Z",
     "shell.execute_reply": "2024-05-23T15:11:34.283564Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.282171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_process = IterableChain(\n",
    "            ISeqLenLimit(max_seq_len=512),\n",
    "            FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            GetSplit(start_month=1, end_month=12),\n",
    "            ToTorch()\n",
    ")\n",
    "\n",
    "test_process = IterableChain(\n",
    "            ISeqLenLimit(max_seq_len=512),\n",
    "            FeatureFilter(keep_feature_names=['client_id'], drop_feature_names=['target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            ToTorch()\n",
    ")\n",
    "\n",
    "\n",
    "train = ParquetDataset([train_data_path], post_processing=train_process)\n",
    "test = ParquetDataset([valid_data_path], post_processing=test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6989271-0c43-4b64-8d28-1a10494a2233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.283791Z",
     "iopub.status.busy": "2024-05-23T15:11:34.283742Z",
     "iopub.status.idle": "2024-05-23T15:11:34.285140Z",
     "shell.execute_reply": "2024-05-23T15:11:34.285076Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.283766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_train_dl = DataLoader(\n",
    "        dataset=train,\n",
    "        collate_fn=partial(collate_feature_dict_with_target, targets=True),\n",
    "        shuffle=False,\n",
    "        num_workers=16,\n",
    "        batch_size=32,\n",
    "    )\n",
    "\n",
    "inference_test_dl = DataLoader(\n",
    "        dataset=test,\n",
    "        collate_fn=collate_feature_dict_with_target,\n",
    "        shuffle=False,\n",
    "        num_workers=16,\n",
    "        batch_size=32,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb97e8e1-daeb-46a2-940c-0d2ff013b3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.285286Z",
     "iopub.status.busy": "2024-05-23T15:11:34.285239Z",
     "iopub.status.idle": "2024-05-23T15:11:34.286195Z",
     "shell.execute_reply": "2024-05-23T15:11:34.286137Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.285261Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_module = InferenceModuleMultimodal(\n",
    "        model=model,\n",
    "        pandas_output=True,\n",
    "        drop_seq_features=True,\n",
    "        model_out_name='emb',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e5cfd-2e71-4f5c-a507-f6bc02785596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.286331Z",
     "iopub.status.busy": "2024-05-23T15:11:34.286284Z",
     "iopub.status.idle": "2024-05-23T15:11:34.289464Z",
     "shell.execute_reply": "2024-05-23T15:11:34.289399Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.286306Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=[0], max_epochs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd052e-3a57-4226-95cb-357d65a04ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:11:34.289585Z",
     "iopub.status.busy": "2024-05-23T15:11:34.289539Z",
     "iopub.status.idle": "2024-05-23T15:12:23.217020Z",
     "shell.execute_reply": "2024-05-23T15:12:23.214900Z",
     "shell.execute_reply.started": "2024-05-23T15:11:34.289560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_test_embeddings = pd.concat(\n",
    "        trainer.predict(inf_module, inference_test_dl)\n",
    "    )\n",
    "inf_test_embeddings.to_parquet(\"geo_baseline_tabformer_test.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d36b1eb-5a96-4ebf-9a61-15e1a2660d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:12:23.223640Z",
     "iopub.status.busy": "2024-05-23T15:12:23.223120Z",
     "iopub.status.idle": "2024-05-23T15:12:23.332070Z",
     "shell.execute_reply": "2024-05-23T15:12:23.331140Z",
     "shell.execute_reply.started": "2024-05-23T15:12:23.22339Z"
    }
   },
   "outputs": [],
   "source": [
    "del inf_test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0113d8a-b3b9-45a5-b57c-982b58b5e7ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T15:12:23.333730Z",
     "iopub.status.busy": "2024-05-23T15:12:23.333200Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_train_embeddings = pd.concat(\n",
    "        trainer.predict(inf_module, inference_train_dl)\n",
    "    )\n",
    "inf_train_embeddings.to_parquet(\"geo_baseline_tabformer_train.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74cb9b-f2a5-480c-b96c-6cfe5f71ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "del inf_train_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dfbdfd-3e82-4305-80f7-07891be5469e",
   "metadata": {},
   "source": [
    "# Downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762006c9-cf4c-41db-88db-ab595efeff41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Downstream:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path,\n",
    "        test_path,\n",
    "        params,\n",
    "        result_path,\n",
    "        col_id='client_id',\n",
    "        targets=(\n",
    "            'target_1',\n",
    "            'target_2',\n",
    "            'target_3',\n",
    "            'target_4'\n",
    "        )\n",
    "    ):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "\n",
    "        self.col_id = col_id\n",
    "        self.all_targets = targets\n",
    "        self.params = params\n",
    "        self.result_path = result_path\n",
    "        self.drop_feat = list(self.all_targets) + [self.col_id]\n",
    "        \n",
    "    def fit(self):\n",
    "        \n",
    "        train_embeddings = pd.read_parquet(self.train_path)\n",
    "        X_train = train_embeddings.drop(columns=self.drop_feat)\n",
    "\n",
    "        clfs = dict()\n",
    "        for col_target in self.all_targets:\n",
    "            clf = ltb.LGBMClassifier(**self.params)\n",
    "            y_train = train_embeddings[col_target]\n",
    "            clf.fit(X_train, y_train)\n",
    "            print(f'Model fitted, target: {col_target}')\n",
    "            clfs[col_target] = clf\n",
    "        return clfs\n",
    "\n",
    "    def get_scores(\n",
    "        self, \n",
    "        clfs\n",
    "    ):\n",
    "        scores = pd.DataFrame([])\n",
    "\n",
    "        test_embeddings_curr = pd.read_parquet(self.test_path).drop_duplicates('client_id')\n",
    "        X_test = test_embeddings_curr.drop(columns=[self.col_id])\n",
    "        ids = test_embeddings_curr[self.col_id]\n",
    "        scores[self.col_id] = ids\n",
    "            \n",
    "        for col_target in self.all_targets:\n",
    "            clf = clfs[col_target]\n",
    "            score = clf.predict_proba(X_test)[:, 1]\n",
    "            scores[col_target] = score\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    def run(self):\n",
    "        clfs = self.fit()\n",
    "        scores = self.get_scores(clfs)\n",
    "        \n",
    "        scores.to_csv(self.result_path)\n",
    "            \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d372e4-c33e-45f8-8eec-b254b64791d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      \"objective\": \"binary\",\n",
    "      \"subsample\": 0.5,\n",
    "      \"subsample_freq\": 1,\n",
    "      \"learning_rate\": 0.02,\n",
    "      \"feature_fraction\": 0.75,\n",
    "      \"max_depth\": 6,\n",
    "      \"lambda_l1\": 1,\n",
    "      \"lambda_l2\": 1,\n",
    "      \"min_data_in_leaf\": 50,\n",
    "      \"random_state\": 42,\n",
    "      \"n_jobs\": 8,\n",
    "}\n",
    "\n",
    "dw = Downstream(\n",
    "    train_path=\"geo_baseline_tabformer_train.parquet\",\n",
    "    test_path=\"geo_baseline_tabformer_test.parquet\",\n",
    "    params=params,\n",
    "    result_path='baseline_tabformer_geo.csv' \n",
    ")\n",
    "\n",
    "scores = dw.run()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3395c-6fc8-47d0-9e0e-0cdda54dec62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! python ../scripts/evaluate.py --ref_df_public public_target.parquet --ref_df_private private_target.parquet --pred_df baseline_tabformer_geo.csv --public_result_path public_tabformer_geo_score.txt --private_result_path private_tabformer_geo_score.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec28c4d-b237-4f82-9a12-1d0b7bb793e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e89d32-8ff0-4219-8d8f-307299880d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XPython Python 3.8.8",
   "language": "python",
   "name": "xpython38"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
