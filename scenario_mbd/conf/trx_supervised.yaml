fold: 4
defaults:
  - _self_
  - dataset_unsupervised/parquet_supervised_trx
  - inference/inference_trx

seed_everything: 42
logger_name: trx_supervised_${fold}
model_path: scenario_mbd/models/${logger_name}.p

inference_run: false
downstream_run: false

supervised_settings: true

data_module:
  _target_: ptls.frames.PtlsDataModule
  train_data:
    _target_: ptls.frames.supervised.SeqToTargetIterableDataset
    target_col_name: targets
    target_dtype: int
    data: ${dataset_unsupervised.train}
  valid_data:
    _target_: ptls.frames.supervised.SeqToTargetIterableDataset
    target_col_name: targets
    target_dtype: int
    data: ${dataset_unsupervised.valid}
  train_batch_size: 512
  train_num_workers: 16
  valid_batch_size: 128
  valid_num_workers: 16

trainer:
  accelerator: gpu
  max_epochs: 30
  gradient_clip_val: 0.5
  checkpoints_every_n_val_epochs: 1
  fast_dev_run: false


pl_module:
  _target_: ptls.frames.supervised.SequenceToTarget
  metric_list:
    _target_: torchmetrics.AUROC
    task: multilabel
  loss: 
    _target_: torch.nn.BCELoss
  head: 
    _target_: torch.nn.Sequential
    _args_:
      - _target_: torch.nn.Linear
        in_features: 64
        out_features: 4
      - _target_: torch.nn.Sigmoid
  seq_encoder:
    _target_: ptls.nn.RnnSeqEncoder
    trx_encoder:
      _target_: ptls.nn.TrxEncoder
      norm_embeddings: false
      embeddings_noise: 0.003
      embeddings:
        event_type:
          in: 58
          out: 24
        event_subtype:
          in: 59
          out: 24
        src_type11:
          in: 85
          out: 24
        src_type12:
          in: 349
          out: 24
        dst_type11:
          in: 84
          out: 24
        dst_type12:
          in: 417
          out: 12
        src_type22:
          in: 90
          out: 24
        src_type32:
          in: 91
          out: 24
      numeric_values:
        amount: log
    type: gru
    hidden_size: 256
  optimizer_partial:
    _partial_: true
    _target_: torch.optim.AdamW
    lr: 0.0001
  lr_scheduler_partial:
    _partial_: true
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 3
    gamma: 0.9025