{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e62b2f76-81e1-4693-8d22-dead6fc1230c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-26T09:06:49.875026Z",
     "iopub.status.busy": "2024-05-26T09:06:49.874940Z",
     "iopub.status.idle": "2024-05-26T09:06:49.877108Z",
     "shell.execute_reply": "2024-05-26T09:06:49.877035Z",
     "shell.execute_reply.started": "2024-05-26T09:06:49.874994Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "from ptls.data_load import IterableChain\n",
    "from datetime import datetime\n",
    "from ptls.data_load.datasets.parquet_dataset import ParquetDataset, ParquetFiles\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "import torch\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader\n",
    "from ptls.data_load.padded_batch import PaddedBatch\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3feffeb4-3d93-404b-bd3f-295d0284f01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:48:19.842365Z",
     "iopub.status.busy": "2024-05-25T11:48:19.842314Z",
     "iopub.status.idle": "2024-05-25T11:48:19.843090Z",
     "shell.execute_reply": "2024-05-25T11:48:19.843028Z",
     "shell.execute_reply.started": "2024-05-25T11:48:19.842335Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = 'dial_train_prepr.parquet'\n",
    "valid_data_path = 'dial_test_prepr.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3b926d-6ad8-4dc1-aa63-a62e5688b4bb",
   "metadata": {},
   "source": [
    "# Last embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3e678-001c-416d-93d3-a40e5821f6ef",
   "metadata": {},
   "source": [
    "## Usefull function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c282dc5-db3b-4757-853e-ddb375fa078f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:48:21.968393Z",
     "iopub.status.busy": "2024-05-25T11:48:21.968309Z",
     "iopub.status.idle": "2024-05-25T11:48:21.975208Z",
     "shell.execute_reply": "2024-05-25T11:48:21.975142Z",
     "shell.execute_reply.started": "2024-05-25T11:48:21.968358Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GetSplit(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_month,\n",
    "        end_month,\n",
    "        year=2022,\n",
    "        col_id='client_id',\n",
    "        col_time='event_time'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start_month = start_month\n",
    "        self.end_month = end_month\n",
    "        self._year = year\n",
    "        self._col_id = col_id\n",
    "        self._col_time = col_time\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for rec in self._src:\n",
    "            for month in range(self.start_month, self.end_month+1):\n",
    "                features = rec[0] if type(rec) is tuple else rec\n",
    "                features = features.copy()\n",
    "                \n",
    "                if month == 12:\n",
    "                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n",
    "                else:\n",
    "                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n",
    "                    \n",
    "                year_event_time = datetime(self._year, 1, 1).timestamp()\n",
    "                \n",
    "                mask = features[self._col_time] < month_event_time\n",
    "                \n",
    "                for key, tens in features.items():\n",
    "                    if key.startswith('target'):\n",
    "                        features[key] = tens[month - 1].tolist()    \n",
    "                    elif key == 'embedding':\n",
    "                        features[key] = torch.tensor(tens.tolist())[mask]\n",
    "                        if len(features[key]) > 1:\n",
    "                            features[key] = features[key][-1]\n",
    "                        elif len(features[key]) == 1:\n",
    "                            features[key] = features[key][0]\n",
    "                        elif len(features[key]) == 0:\n",
    "                            features[key] = torch.zeros(768)\n",
    "                            \n",
    "                features[self._col_id] += '_month=' + str(month)\n",
    "\n",
    "                yield features\n",
    "\n",
    "def collate_feature_dict_with_target(batch, col_id='client_id', targets=False):\n",
    "    batch_ids = []\n",
    "    target_cols = []\n",
    "    for sample in batch:\n",
    "        batch_ids.append(sample[col_id])\n",
    "        del sample[col_id]\n",
    "        \n",
    "        if targets:\n",
    "            target_cols.append([sample[f'target_{i}'] for i in range(1, 5)])\n",
    "            del sample['target_1']\n",
    "            del sample['target_2']\n",
    "            del sample['target_3']\n",
    "            del sample['target_4']\n",
    "            \n",
    "    padded_batch = collate_feature_dict(batch)\n",
    "    if targets:\n",
    "        return padded_batch, batch_ids, target_cols\n",
    "    return padded_batch, batch_ids    \n",
    "\n",
    "def to_pandas(x):\n",
    "    expand_cols = []\n",
    "    scalar_features = {}\n",
    "\n",
    "    for k, v in x.items():\n",
    "        if type(v) is torch.Tensor:\n",
    "            v = v.cpu().numpy()\n",
    "\n",
    "        if type(v) is list or len(v.shape) == 1:\n",
    "            scalar_features[k] = v\n",
    "        elif len(v.shape) == 2:\n",
    "            expand_cols.append(k)\n",
    "        else:\n",
    "            scalar_features[k] = None\n",
    "\n",
    "    dataframes = [pd.DataFrame(scalar_features)]\n",
    "    for col in expand_cols:\n",
    "        v = x[col].cpu().numpy()\n",
    "        dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n",
    "\n",
    "    return pd.concat(dataframes, axis=1)\n",
    "\n",
    "def get_dataset(dl, target=True):\n",
    "    dataset = []\n",
    "    for batch in tqdm(dl):\n",
    "        if target:\n",
    "            out, batch_ids, target_cols = batch[0].payload['embedding'], batch[1], np.squeeze([batch[2]])\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'target_1': target_cols[:, 0],\n",
    "                'target_2': target_cols[:, 1],\n",
    "                'target_3': target_cols[:, 2],\n",
    "                'target_4': target_cols[:, 3],\n",
    "                'embs': out\n",
    "            }\n",
    "        else:\n",
    "            out, batch_ids = batch[0].payload['embedding'], batch[1]\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'embs': out\n",
    "            }\n",
    "        dataset.append(to_pandas(x_out))\n",
    "    return pd.concat(dataset, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9a060d-b07c-472a-9f02-a89106a07a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:48:23.365493Z",
     "iopub.status.busy": "2024-05-25T11:48:23.365399Z",
     "iopub.status.idle": "2024-05-25T11:48:23.367194Z",
     "shell.execute_reply": "2024-05-25T11:48:23.367128Z",
     "shell.execute_reply.started": "2024-05-25T11:48:23.365462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToTorchTmpLast(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for rec in self._src:\n",
    "            features = rec[0] if type(rec) is tuple else rec\n",
    "            features = features.copy()\n",
    "            for key, tens in features.items():\n",
    "                if key == 'embedding':\n",
    "                    features[key] = torch.tensor(tens.tolist())\n",
    "                    if len(features[key]) > 1:\n",
    "                        features[key] = features[key][-1]#torch.mean(features[key], dim=0)\n",
    "                    elif len(features[key]) == 1:\n",
    "                        features[key] = features[key][0]\n",
    "                    elif len(features[key]) == 0:\n",
    "                        features[key] = torch.zeros(768)\n",
    "\n",
    "            yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9bb30b-d0cc-4518-9eeb-936b7da67dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:48:34.786762Z",
     "iopub.status.busy": "2024-05-25T11:48:34.786670Z",
     "iopub.status.idle": "2024-05-25T11:48:34.789583Z",
     "shell.execute_reply": "2024-05-25T11:48:34.789503Z",
     "shell.execute_reply.started": "2024-05-25T11:48:34.786734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_process = IterableChain(\n",
    "            FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            GetSplit(start_month=1, end_month=12),\n",
    "            ToTorch(),\n",
    ")\n",
    "\n",
    "test_process = IterableChain(\n",
    "            FeatureFilter(keep_feature_names=['client_id'], drop_feature_names=['target_1', 'target_2', 'target_3', 'target_4']),\n",
    "            ToTorchTmpLast(),\n",
    "            ToTorch()\n",
    ")\n",
    "\n",
    "\n",
    "train = ParquetDataset([train_data_path], post_processing=train_process)\n",
    "test = ParquetDataset([valid_data_path], post_processing=test_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a33f588-1b7a-447a-8e94-322a7d389b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:48:37.965152Z",
     "iopub.status.busy": "2024-05-25T11:48:37.965054Z",
     "iopub.status.idle": "2024-05-25T11:48:37.967074Z",
     "shell.execute_reply": "2024-05-25T11:48:37.966993Z",
     "shell.execute_reply.started": "2024-05-25T11:48:37.965123Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_train_dl = DataLoader(\n",
    "        dataset=train,\n",
    "        collate_fn=partial(collate_feature_dict_with_target, targets=True),\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        batch_size=512,\n",
    "    )\n",
    "\n",
    "inference_test_dl = DataLoader(\n",
    "        dataset=test,\n",
    "        collate_fn=collate_feature_dict_with_target,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        batch_size=512,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aeb1b7-18ec-48ff-97fa-c1a618d9156e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T11:49:03.427659Z",
     "iopub.status.busy": "2024-05-25T11:49:03.427504Z",
     "iopub.status.idle": "2024-05-25T17:24:47.137872Z",
     "shell.execute_reply": "2024-05-25T17:24:47.137727Z",
     "shell.execute_reply.started": "2024-05-25T11:49:03.427625Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(inference_train_dl)\n",
    "train_dataset.to_parquet(\"dial_last_baseline_train.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")\n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca4c69-7129-4037-9cfd-346714428629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T17:24:47.138261Z",
     "iopub.status.busy": "2024-05-25T17:24:47.138190Z",
     "iopub.status.idle": "2024-05-25T17:25:08.977297Z",
     "shell.execute_reply": "2024-05-25T17:25:08.977086Z",
     "shell.execute_reply.started": "2024-05-25T17:24:47.138235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = get_dataset(inference_test_dl, target=False)\n",
    "test_dataset.to_parquet(\"dial_last_baseline_test.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")\n",
    "del test_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XPython Python 3.8.8",
   "language": "python",
   "name": "xpython38"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
